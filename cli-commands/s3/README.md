# ğŸ“Œ AWS S3 â€“ Kompletny Poradnik CLI, Polityki, Montowanie

## ğŸ“– Opis
AWS S3 (Simple Storage Service) to skalowalna usÅ‚uga przechowywania danych w chmurze. Ten poradnik obejmuje:
- Tworzenie i zarzÄ…dzanie bucketami S3 w **AWS CLI**.
- **Polityki IAM** do kontroli dostÄ™pu.
- **Montowanie S3 jako dysk sieciowy** w **Windows i macOS**.

---

## ğŸ”¹ 1. Tworzenie i zarzÄ…dzanie bucketami w AWS CLI

### **ğŸ”§ Tworzenie bucketa S3**
```bash
aws s3 mb s3://nazwa-twojego-bucketa --region eu-central-1
```
> ğŸ“Œ Bucket musi mieÄ‡ unikalnÄ… nazwÄ™ globalnie.

### **ğŸ“œ Lista bucketÃ³w**
```bash
aws s3 ls
```

### **ğŸ“‚ WysyÅ‚anie plikÃ³w**
```bash
aws s3 cp lokalny_plik.txt s3://nazwa-twojego-bucketa/
```

### **ğŸ“¥ Pobieranie plikÃ³w**
```bash
aws s3 cp s3://nazwa-twojego-bucketa/lokalny_plik.txt .
```

### **ğŸ—‘ï¸ UsuniÄ™cie bucketa**
```bash
aws s3 rb s3://nazwa-twojego-bucketa --force
```

---

## ğŸ”¹ 2. Polityki IAM dla S3

### **ğŸ“œ Publiczny dostÄ™p do wszystkich obiektÃ³w w bucketach** *(Uwaga: kaÅ¼dy ma dostÄ™p!)*
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": "*",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::nazwa-twojego-bucketa/*"
        }
    ]
}
```
ğŸ“Œ **Zastosowanie:**
- **AWS Console** â†’ **S3** â†’ **Permissions** â†’ **Bucket Policy**.
- Wklej politykÄ™ i **zapisz zmiany**.

### **ğŸ”’ Prywatny dostÄ™p tylko dla wÅ‚aÅ›ciciela**
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Deny",
            "Principal": "*",
            "Action": "s3:*",
            "Resource": "arn:aws:s3:::nazwa-twojego-bucketa/*"
        }
    ]
}
```
ğŸ“Œ **Blokuje dostÄ™p dla wszystkich poza wÅ‚aÅ›cicielem.**
#### Przekazanie polityki z pliku JSON
```bash
aws s3api put-bucket-policy \
    --bucket nazwa-twojego-bucketu \
    --policy file://bucket_policy.json
```
#### Sprawdzenie aktualnej polityki
```bash
aws s3api get-bucket-policy \
    --bucket nazwa-twojego-bucketu
```
---

## ğŸ”¹ 3. Montowanie S3 jako dysk w Windows

### **ğŸ›  Metoda 1: Rclone (zalecana)**
#### **1ï¸âƒ£ Instalacja Rclone**
```bash
winget install Rclone
```
#### **2ï¸âƒ£ Konfiguracja dostÄ™pu do AWS**
```bash
rclone config
```
- Wybierz `New remote`
- Nazwa np. **myS3**
- Typ: **s3**
- Wpisz **AWS Access Key ID** i **Secret Access Key**
- Region: `eu-central-1`

#### **3ï¸âƒ£ Montowanie bucketa jako dysk X:**
```bash
rclone mount myS3:nazwa-twojego-bucketa X: --vfs-cache-mode full
```
#### **4ï¸âƒ£ Automatyczne montowanie po restarcie**
Dodaj do **Task Scheduler**:
```bash
rclone mount myS3:nazwa-twojego-bucketa X: --vfs-cache-mode full
```

---

### **ğŸ›  Metoda 2: s3fs + WinFsp**
#### **1ï¸âƒ£ Instalacja zaleÅ¼noÅ›ci**
```bash
winget install WinFsp
winget install s3fs
```
#### **2ï¸âƒ£ Konfiguracja pliku z poÅ›wiadczeniami**
```bash
echo "AWS_ACCESS_KEY_ID:AWS_SECRET_ACCESS_KEY" > C:\Users\TwojeKonto\.passwd-s3fs
icacls C:\Users\TwojeKonto\.passwd-s3fs /grant TwojeKonto:F
```
#### **3ï¸âƒ£ Montowanie bucketa jako dysk X:**
```bash
s3fs nazwa-twojego-bucketa X: -o passwd_file=C:\Users\TwojeKonto\.passwd-s3fs -o url=https://s3.eu-central-1.amazonaws.com
```

---

## ğŸ”¹ 4. Montowanie S3 jako dysk w macOS

### **ğŸ›  Metoda 1: Rclone (zalecana)**
#### **1ï¸âƒ£ Instalacja Rclone**
```bash
brew install rclone
```
#### **2ï¸âƒ£ Konfiguracja dostÄ™pu do AWS**
```bash
rclone config
```
#### **3ï¸âƒ£ Montowanie S3 jako `/Volumes/S3`**
```bash
mkdir -p /Volumes/S3
rclone mount myS3:nazwa-twojego-bucketa /Volumes/S3 --daemon
```
#### **4ï¸âƒ£ Automatyczne montowanie po restarcie**
Dodaj do `crontab`:
```bash
@reboot /usr/local/bin/rclone mount myS3:nazwa-twojego-bucketa /Volumes/S3 --daemon
```

---

### **ğŸ›  Metoda 2: s3fs**
#### **1ï¸âƒ£ Instalacja s3fs**
```bash
brew install s3fs
```
#### **2ï¸âƒ£ Konfiguracja pliku z poÅ›wiadczeniami**
```bash
echo "AWS_ACCESS_KEY_ID:AWS_SECRET_ACCESS_KEY" > ~/.passwd-s3fs
chmod 600 ~/.passwd-s3fs
```
#### **3ï¸âƒ£ Montowanie S3 jako `/Volumes/S3`**
```bash
mkdir -p /Volumes/S3
s3fs nazwa-twojego-bucketa /Volumes/S3 -o passwd_file=~/.passwd-s3fs -o allow_other -o url=https://s3.eu-central-1.amazonaws.com
```

---

## âœ… Podsumowanie
| Metoda | Windows | macOS | Zalety |
|--------|---------|--------|--------|
| **Rclone** | âœ… | âœ… | Proste, szybkie, stabilne |
| **s3fs** | âœ… | âœ… | PeÅ‚na integracja z systemem |

ğŸ“Œ **Rekomendacja**: **UÅ¼yj Rclone, jeÅ›li potrzebujesz prostego montowania.** JeÅ›li chcesz peÅ‚nej integracji â€“ **s3fs**.

---
# Automatyczny Multipart Upload w AWS S3

## 1. Wprowadzenie

Amazon S3 umoÅ¼liwia **wieloczÄ™Å›ciowe (multipart) przesyÅ‚anie plikÃ³w** â€“ szczegÃ³lnie przydatne w przypadku obiektÃ³w powyÅ¼ej 8 MB. DziÄ™ki temu:

- PrzesyÅ‚anie duÅ¼ych plikÃ³w jest **bardziej niezawodne** (bÅ‚Ä…d na jednej czÄ™Å›ci nie przerywa caÅ‚ej operacji).
- ZwiÄ™ksza siÄ™ **przepustowoÅ›Ä‡** dziÄ™ki przesyÅ‚aniu czÄ™Å›ci rÃ³wnolegle.
- AWS CLI moÅ¼e **automatycznie** uruchomiÄ‡ wieloczÄ™Å›ciowy upload bez rÄ™cznej konfiguracji.

## 2. Automatyczny multipart upload w AWS CLI

### a) DomyÅ›lne zachowanie

W AWS Command Line Interface (CLI) wystarczy uÅ¼yÄ‡ prostego polecenia kopiowania do S3:

```bash
aws s3 cp /Å›cieÅ¼ka/do/duÅ¼ego_pliku s3://nazwa-twojego-bucketu/
```

JeÅ›li plik przekracza **8 MB**, CLI **automatycznie** dzieli go na mniejsze czÄ™Å›ci, przesyÅ‚a kaÅ¼dÄ… czÄ™Å›Ä‡ i na koÅ„cu scala je w jeden obiekt w S3.

### b) Wymuszenie parametrÃ³w multipart

MoÅ¼emy jawnie okreÅ›liÄ‡ rozmiar czÄ™Å›ci i inne parametry. PrzykÅ‚adowo:

```bash
aws s3 cp /Å›cieÅ¼ka/do/duÅ¼ego_pliku s3://nazwa-twojego-bucketu/ \
  --multipart-chunk-size-mb 64 \
  --expected-size 200MB
```

- `--multipart-chunk-size-mb 64` ustawia rozmiar kaÅ¼dej czÄ™Å›ci na 64 MB.
- `--expected-size` pozwala podaÄ‡ spodziewany rozmiar przesyÅ‚anego pliku.

## 3. Automatyczny multipart upload w Pythonie (boto3)

ChoÄ‡ AWS CLI to najszybsza droga, moÅ¼na teÅ¼ uÅ¼yÄ‡ **boto3** w Pythonie. Ta biblioteka ma wbudowane funkcje, ktÃ³re za nas wykonujÄ… wieloczÄ™Å›ciowe przesyÅ‚anie.

### a) Szybki przykÅ‚ad z `upload_file`

```python
import boto3

s3_client = boto3.client('s3')
bucket_name = "nazwa-twojego-bucketu"
source_file_path = "/Å›cieÅ¼ka/do/duÅ¼ego_pliku"
destination_key = "upload/test_pliku"

s3_client.upload_file(
    Filename=source_file_path,
    Bucket=bucket_name,
    Key=destination_key
)
```

boto3 automatycznie wykryje wiÄ™kszy plik i uruchomi **multipart upload**. Nie trzeba nic wiÄ™cej konfigurowaÄ‡.

### b) Konfiguracja z `TransferConfig`

JeÅ¼eli chcesz dostosowaÄ‡ parametry (np. rozmiar czÄ™Å›ci, liczbÄ™ wÄ…tkÃ³w), uÅ¼yj `TransferConfig`:

```python
from boto3.s3.transfer import TransferConfig

MB = 1024 * 1024

config = TransferConfig(
    multipart_threshold=8 * MB,
    multipart_chunksize=64 * MB,
    max_concurrency=10
)

s3_client.upload_file(
    Filename=source_file_path,
    Bucket=bucket_name,
    Key=destination_key,
    Config=config
)
```

DziÄ™ki temu:
- Gdy plik przekracza 8 MB (`multipart_threshold`), to boto3 dzieli go na 64 MB czÄ™Å›ci (`multipart_chunksize`).
- `max_concurrency=10` ustala liczbÄ™ wÄ…tkÃ³w rÃ³wnolegle wysyÅ‚ajÄ…cych czÄ™Å›ci.

## 4. Zalety automatycznego multipart upload

1. **NiezawodnoÅ›Ä‡**: MoÅ¼esz wznawiaÄ‡ upload od czÄ™Å›ci, ktÃ³ra ulegÅ‚a awarii, zamiast przesyÅ‚aÄ‡ caÅ‚oÅ›Ä‡ od nowa.
2. **WydajnoÅ›Ä‡**: RÃ³wnolegÅ‚e przesyÅ‚anie czÄ™Å›ci znaczÄ…co skraca czas uploadu.
3. **ÅatwoÅ›Ä‡ uÅ¼ycia**: Wystarczy wykonaÄ‡ `aws s3 cp` (CLI) albo `upload_file` (boto3) â€“ resztÄ… zajmuje siÄ™ AWS.

## 5. Podsumowanie

- **AWS CLI** automatycznie wÅ‚Ä…cza wieloczÄ™Å›ciowy transfer dla plikÃ³w powyÅ¼ej 8 MB.
- **boto3** rÃ³wnieÅ¼ wykonuje to automatycznie, a dodatkowo moÅ¼esz kontrolowaÄ‡ ten proces poprzez `TransferConfig`.
- PrzesyÅ‚aj duÅ¼e pliki do S3 **szybko** i **bezpiecznie** â€“ bez koniecznoÅ›ci dzielenia ich manualnie.

